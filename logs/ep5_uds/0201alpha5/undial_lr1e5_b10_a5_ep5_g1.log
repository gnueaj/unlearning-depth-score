Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
================================================================================
S1/S2 Experiment with Teacher Forcing (Side-by-Side)
================================================================================
Mode: layer
Metric: logprob
Delta threshold: 0.05
EM scope: entity
Entity source: gt
Reference scope: continuation
Patch scope: span
Unlearn model: undial_lr1e5_b10_a5_ep5

Loading models...
Loading unlearn model: open-unlearning/unlearn_tofu_Llama-3.2-1B-Instruct_forget10_UNDIAL_lr1e-05_beta10_alpha5_epoch5
Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
Loaded 367 examples

========================================
Running S1/S2 (layer, teacher forcing)
========================================
S1/S2 layer:   0%|          | 0/367 [00:00<?, ?it/s]S1/S2 layer:   0%|          | 1/367 [00:01<07:03,  1.16s/it]S1/S2 layer:   1%|          | 2/367 [00:02<07:05,  1.17s/it]S1/S2 layer:   1%|          | 3/367 [00:03<06:45,  1.11s/it]S1/S2 layer:   1%|          | 4/367 [00:04<06:16,  1.04s/it]S1/S2 layer:   1%|▏         | 5/367 [00:05<06:36,  1.09s/it]S1/S2 layer:   2%|▏         | 6/367 [00:06<06:55,  1.15s/it]S1/S2 layer:   2%|▏         | 7/367 [00:07<06:41,  1.11s/it]S1/S2 layer:   2%|▏         | 8/367 [00:08<06:23,  1.07s/it]S1/S2 layer:   2%|▏         | 9/367 [00:09<06:32,  1.10s/it]S1/S2 layer:   3%|▎         | 10/367 [00:11<06:52,  1.16s/it]S1/S2 layer:   3%|▎         | 11/367 [00:12<07:09,  1.21s/it]S1/S2 layer:   3%|▎         | 12/367 [00:13<07:19,  1.24s/it]S1/S2 layer:   4%|▎         | 13/367 [00:15<07:27,  1.26s/it]S1/S2 layer:   4%|▍         | 14/367 [00:16<07:21,  1.25s/it]S1/S2 layer:   4%|▍         | 15/367 [00:17<07:29,  1.28s/it]S1/S2 layer:   4%|▍         | 16/367 [00:18<07:19,  1.25s/it]S1/S2 layer:   5%|▍         | 17/367 [00:19<06:29,  1.11s/it]S1/S2 layer:   5%|▍         | 18/367 [00:20<06:31,  1.12s/it]S1/S2 layer:   5%|▌         | 19/367 [00:22<06:53,  1.19s/it]S1/S2 layer:   5%|▌         | 20/367 [00:23<06:18,  1.09s/it]S1/S2 layer:   6%|▌         | 21/367 [00:23<05:45,  1.00it/s]S1/S2 layer:   6%|▌         | 22/367 [00:25<06:13,  1.08s/it]S1/S2 layer:   6%|▋         | 23/367 [00:26<06:36,  1.15s/it]S1/S2 layer:   7%|▋         | 24/367 [00:27<06:26,  1.13s/it]S1/S2 layer:   7%|▋         | 25/367 [00:28<06:37,  1.16s/it]S1/S2 layer:   7%|▋         | 26/367 [00:30<06:52,  1.21s/it]S1/S2 layer:   7%|▋         | 27/367 [00:31<06:57,  1.23s/it]S1/S2 layer:   7%|▋         | 27/367 [00:32<06:51,  1.21s/it]
Traceback (most recent call last):
  File "/home/jaeung/activation-patching-unlearning/exp_s1_teacher_forcing.py", line 1135, in main
    results, gk_count, categories, avg_udr, skipped_indices = run_s1_s2_side_by_side(
  File "/home/jaeung/activation-patching-unlearning/exp_s1_teacher_forcing.py", line 951, in run_s1_s2_side_by_side
    log_file.flush()
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaeung/activation-patching-unlearning/exp_s1_teacher_forcing.py", line 1205, in <module>
    main()
  File "/home/jaeung/activation-patching-unlearning/exp_s1_teacher_forcing.py", line 1173, in main
    print(summary_msg)
OSError: [Errno 28] No space left on device
