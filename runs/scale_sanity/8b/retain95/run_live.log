================================================================================
S1/S2 Experiment with Teacher Forcing (Side-by-Side)
================================================================================
Mode: layer
Metric: logprob
Delta threshold: 0.05
EM scope: entity
Entity source: gt
Reference scope: continuation
Patch scope: span
Batch size: 2
Full model: open-unlearning/tofu_Llama-3.1-8B-Instruct_full
Retain model: open-unlearning/tofu_Llama-3.1-8B-Instruct_retain90
Dtype: bfloat16
Device map: auto
Unlearn model: open-unlearning/tofu_Llama-3.1-8B-Instruct_retain95

Loading models...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.96s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.74s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.29s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.29s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.00it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]
Loading unlearn model: open-unlearning/tofu_Llama-3.1-8B-Instruct_retain95
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Fetching 4 files:  25%|██▌       | 1/4 [02:17<06:51, 137.06s/it]Fetching 4 files:  50%|█████     | 2/4 [02:46<02:27, 73.98s/it] Fetching 4 files: 100%|██████████| 4/4 [02:46<00:00, 41.72s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.77it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]
Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
Loaded 367 examples
Using first 367 examples

========================================
Running S1/S2 (layer, teacher forcing)
========================================
S1/S2 layer (batched):   0%|          | 0/367 [00:00<?, ?it/s]S1/S2 layer (batched):   0%|          | 1/367 [00:01<11:20,  1.86s/it]S1/S2 layer (batched):   1%|          | 2/367 [00:05<18:10,  2.99s/it]S1/S2 layer (batched):   1%|          | 3/367 [00:07<14:20,  2.36s/it]S1/S2 layer (batched):   1%|          | 4/367 [00:11<17:43,  2.93s/it]S1/S2 layer (batched):   1%|▏         | 5/367 [00:12<14:51,  2.46s/it]S1/S2 layer (batched):   2%|▏         | 6/367 [00:16<17:41,  2.94s/it]S1/S2 layer (batched):   2%|▏         | 7/367 [00:18<15:05,  2.52s/it]S1/S2 layer (batched):   2%|▏         | 8/367 [00:22<17:34,  2.94s/it]S1/S2 layer (batched):   2%|▏         | 9/367 [00:23<15:06,  2.53s/it]S1/S2 layer (batched):   3%|▎         | 10/367 [00:27<17:32,  2.95s/it]S1/S2 layer (batched):   3%|▎         | 11/367 [00:29<15:06,  2.55s/it]S1/S2 layer (batched):   3%|▎         | 12/367 [00:33<18:50,  3.18s/it]S1/S2 layer (batched):   4%|▎         | 13/367 [00:35<16:03,  2.72s/it]S1/S2 layer (batched):   4%|▍         | 14/367 [00:40<19:27,  3.31s/it]S1/S2 layer (batched):   4%|▍         | 15/367 [00:41<16:27,  2.81s/it]S1/S2 layer (batched):   4%|▍         | 16/367 [00:46<19:42,  3.37s/it]S1/S2 layer (batched):   5%|▍         | 17/367 [00:48<16:37,  2.85s/it]S1/S2 layer (batched):   5%|▍         | 18/367 [00:52<19:50,  3.41s/it]S1/S2 layer (batched):   5%|▌         | 19/367 [00:54<16:43,  2.88s/it]S1/S2 layer (batched):   5%|▌         | 20/367 [00:58<18:30,  3.20s/it]S1/S2 layer (batched):   6%|▌         | 21/367 [01:00<15:46,  2.74s/it]S1/S2 layer (batched):   6%|▌         | 22/367 [01:03<17:39,  3.07s/it]S1/S2 layer (batched):   6%|▋         | 23/367 [01:05<15:08,  2.64s/it]S1/S2 layer (batched):   7%|▋         | 24/367 [01:10<18:27,  3.23s/it]S1/S2 layer (batched):   7%|▋         | 25/367 [01:11<15:42,  2.76s/it]S1/S2 layer (batched):   7%|▋         | 26/367 [01:15<17:38,  3.10s/it]S1/S2 layer (batched):   7%|▋         | 27/367 [01:17<15:06,  2.67s/it]S1/S2 layer (batched):   8%|▊         | 28/367 [01:21<17:10,  3.04s/it]S1/S2 layer (batched):   8%|▊         | 29/367 [01:22<14:45,  2.62s/it]S1/S2 layer (batched):   8%|▊         | 30/367 [01:27<18:16,  3.25s/it]S1/S2 layer (batched):   8%|▊         | 31/367 [01:29<15:31,  2.77s/it]S1/S2 layer (batched):   9%|▊         | 32/367 [01:33<17:25,  3.12s/it]S1/S2 layer (batched):   9%|▉         | 33/367 [01:34<14:56,  2.68s/it]S1/S2 layer (batched):   9%|▉         | 34/367 [01:39<18:28,  3.33s/it]S1/S2 layer (batched):  10%|▉         | 35/367 [01:41<15:38,  2.83s/it]S1/S2 layer (batched):  10%|▉         | 36/367 [01:45<17:23,  3.15s/it]S1/S2 layer (batched):  10%|█         | 37/367 [01:46<14:51,  2.70s/it]S1/S2 layer (batched):  10%|█         | 38/367 [01:51<18:09,  3.31s/it]S1/S2 layer (batched):  11%|█         | 39/367 [01:53<15:22,  2.81s/it]S1/S2 layer (batched):  11%|█         | 40/367 [01:57<17:04,  3.13s/it]S1/S2 layer (batched):  11%|█         | 41/367 [01:58<14:36,  2.69s/it]S1/S2 layer (batched):  11%|█▏        | 42/367 [02:02<16:27,  3.04s/it]S1/S2 layer (batched):  12%|█▏        | 43/367 [02:04<14:10,  2.63s/it]S1/S2 layer (batched):  12%|█▏        | 44/367 [02:08<16:17,  3.02s/it]S1/S2 layer (batched):  12%|█▏        | 45/367 [02:10<14:00,  2.61s/it]S1/S2 layer (batched):  13%|█▎        | 46/367 [02:14<17:02,  3.19s/it]S1/S2 layer (batched):  13%|█▎        | 47/367 [02:16<14:33,  2.73s/it]S1/S2 layer (batched):  13%|█▎        | 48/367 [02:20<17:29,  3.29s/it]S1/S2 layer (batched):  13%|█▎        | 49/367 [02:22<14:50,  2.80s/it]S1/S2 layer (batched):  14%|█▎        | 50/367 [02:27<17:40,  3.35s/it]S1/S2 layer (batched):  14%|█▍        | 51/367 [02:28<14:58,  2.84s/it]S1/S2 layer (batched):  14%|█▍        | 52/367 [02:33<17:37,  3.36s/it]S1/S2 layer (batched):  14%|█▍        | 53/367 [02:34<14:53,  2.85s/it]S1/S2 layer (batched):  15%|█▍        | 54/367 [02:39<17:50,  3.42s/it]S1/S2 layer (batched):  15%|█▍        | 55/367 [02:41<15:01,  2.89s/it]S1/S2 layer (batched):  15%|█▌        | 56/367 [02:45<16:31,  3.19s/it]S1/S2 layer (batched):  16%|█▌        | 57/367 [02:46<14:05,  2.73s/it]S1/S2 layer (batched):  16%|█▌        | 58/367 [02:50<15:47,  3.07s/it]S1/S2 layer (batched):  16%|█▌        | 59/367 [02:52<13:33,  2.64s/it]S1/S2 layer (batched):  16%|█▋        | 60/367 [02:57<16:36,  3.25s/it]S1/S2 layer (batched):  17%|█▋        | 61/367 [02:58<14:07,  2.77s/it]S1/S2 layer (batched):  17%|█▋        | 62/367 [03:03<16:46,  3.30s/it]S1/S2 layer (batched):  17%|█▋        | 63/367 [03:04<14:12,  2.81s/it]S1/S2 layer (batched):  17%|█▋        | 64/367 [03:09<17:06,  3.39s/it]S1/S2 layer (batched):  18%|█▊        | 65/367 [03:11<14:25,  2.87s/it]S1/S2 layer (batched):  18%|█▊        | 66/367 [03:15<16:01,  3.19s/it]S1/S2 layer (batched):  18%|█▊        | 67/367 [03:16<13:39,  2.73s/it]S1/S2 layer (batched):  19%|█▊        | 68/367 [03:20<15:25,  3.09s/it]S1/S2 layer (batched):  19%|█▉        | 69/367 [03:22<13:12,  2.66s/it]S1/S2 layer (batched):  19%|█▉        | 70/367 [03:26<15:03,  3.04s/it]S1/S2 layer (batched):  19%|█▉        | 71/367 [03:28<12:56,  2.62s/it]S1/S2 layer (batched):  20%|█▉        | 72/367 [03:32<16:04,  3.27s/it]S1/S2 layer (batched):  20%|█▉        | 73/367 [03:34<13:39,  2.79s/it]S1/S2 layer (batched):  20%|██        | 74/367 [03:38<15:16,  3.13s/it]S1/S2 layer (batched):  20%|██        | 75/367 [03:40<13:03,  2.68s/it]S1/S2 layer (batched):  21%|██        | 76/367 [03:44<16:03,  3.31s/it]S1/S2 layer (batched):  21%|██        | 77/367 [03:46<13:00,  2.69s/it]S1/S2 layer (batched):  21%|██▏       | 78/367 [03:50<16:00,  3.32s/it]S1/S2 layer (batched):  22%|██▏       | 79/367 [03:52<13:34,  2.83s/it]S1/S2 layer (batched):  22%|██▏       | 80/367 [03:58<17:15,  3.61s/it]S1/S2 layer (batched):  22%|██▏       | 81/367 [03:59<14:25,  3.03s/it]S1/S2 layer (batched):  22%|██▏       | 82/367 [04:04<16:37,  3.50s/it]S1/S2 layer (batched):  23%|██▎       | 83/367 [04:05<13:58,  2.95s/it]S1/S2 layer (batched):  23%|██▎       | 84/367 [04:12<19:09,  4.06s/it]S1/S2 layer (batched):  23%|██▎       | 85/367 [04:14<15:44,  3.35s/it]S1/S2 layer (batched):  23%|██▎       | 86/367 [04:18<17:34,  3.75s/it]S1/S2 layer (batched):  24%|██▎       | 87/367 [04:20<14:36,  3.13s/it]S1/S2 layer (batched):  24%|██▍       | 88/367 [04:25<16:59,  3.65s/it]S1/S2 layer (batched):  24%|██▍       | 89/367 [04:27<14:09,  3.06s/it]S1/S2 layer (batched):  25%|██▍       | 90/367 [04:32<17:24,  3.77s/it]S1/S2 layer (batched):  25%|██▍       | 91/367 [04:34<14:27,  3.14s/it]S1/S2 layer (batched):  25%|██▌       | 92/367 [04:38<16:29,  3.60s/it]S1/S2 layer (batched):  25%|██▌       | 93/367 [04:40<13:29,  2.95s/it]S1/S2 layer (batched):  26%|██▌       | 94/367 [04:44<14:46,  3.25s/it]S1/S2 layer (batched):  26%|██▌       | 95/367 [04:46<12:34,  2.77s/it]S1/S2 layer (batched):  26%|██▌       | 96/367 [04:50<15:00,  3.32s/it]S1/S2 layer (batched):  26%|██▋       | 97/367 [04:52<12:44,  2.83s/it]S1/S2 layer (batched):  27%|██▋       | 98/367 [04:56<15:05,  3.37s/it]S1/S2 layer (batched):  27%|██▋       | 99/367 [04:58<12:43,  2.85s/it]S1/S2 layer (batched):  27%|██▋       | 100/367 [05:03<15:16,  3.43s/it]S1/S2 layer (batched):  28%|██▊       | 101/367 [05:05<12:50,  2.90s/it]S1/S2 layer (batched):  28%|██▊       | 102/367 [05:09<14:56,  3.38s/it]S1/S2 layer (batched):  28%|██▊       | 103/367 [05:11<12:36,  2.86s/it]S1/S2 layer (batched):  28%|██▊       | 104/367 [05:15<14:48,  3.38s/it]S1/S2 layer (batched):  29%|██▊       | 105/367 [05:17<12:29,  2.86s/it]S1/S2 layer (batched):  29%|██▉       | 106/367 [05:21<13:47,  3.17s/it]S1/S2 layer (batched):  29%|██▉       | 107/367 [05:22<11:46,  2.72s/it]S1/S2 layer (batched):  29%|██▉       | 108/367 [05:27<14:09,  3.28s/it]S1/S2 layer (batched):  30%|██▉       | 109/367 [05:29<12:00,  2.79s/it]S1/S2 layer (batched):  30%|██▉       | 110/367 [05:33<13:25,  3.14s/it]S1/S2 layer (batched):  30%|███       | 111/367 [05:34<11:28,  2.69s/it]S1/S2 layer (batched):  31%|███       | 112/367 [05:38<13:01,  3.06s/it]S1/S2 layer (batched):  31%|███       | 113/367 [05:40<11:09,  2.64s/it]S1/S2 layer (batched):  31%|███       | 114/367 [05:44<12:40,  3.01s/it]S1/S2 layer (batched):  31%|███▏      | 115/367 [05:45<10:55,  2.60s/it]S1/S2 layer (batched):  32%|███▏      | 116/367 [05:49<12:29,  2.99s/it]S1/S2 layer (batched):  32%|███▏      | 117/367 [05:51<10:45,  2.58s/it]S1/S2 layer (batched):  32%|███▏      | 118/367 [05:56<13:18,  3.21s/it]S1/S2 layer (batched):  32%|███▏      | 119/367 [05:57<11:19,  2.74s/it]S1/S2 layer (batched):  33%|███▎      | 120/367 [06:01<12:43,  3.09s/it]S1/S2 layer (batched):  33%|███▎      | 121/367 [06:03<10:53,  2.66s/it]S1/S2 layer (batched):  33%|███▎      | 122/367 [06:07<12:23,  3.03s/it]S1/S2 layer (batched):  34%|███▎      | 123/367 [06:08<10:39,  2.62s/it]S1/S2 layer (batched):  34%|███▍      | 124/367 [06:13<13:12,  3.26s/it]S1/S2 layer (batched):  34%|███▍      | 125/367 [06:15<11:13,  2.78s/it]S1/S2 layer (batched):  34%|███▍      | 126/367 [06:19<13:17,  3.31s/it]S1/S2 layer (batched):  35%|███▍      | 127/367 [06:21<11:15,  2.82s/it]S1/S2 layer (batched):  35%|███▍      | 128/367 [06:26<13:17,  3.34s/it]S1/S2 layer (batched):  35%|███▌      | 129/367 [06:27<11:15,  2.84s/it]S1/S2 layer (batched):  35%|███▌      | 130/367 [06:31<12:27,  3.15s/it]S1/S2 layer (batched):  36%|███▌      | 131/367 [06:32<10:16,  2.61s/it]S1/S2 layer (batched):  36%|███▌      | 132/367 [06:36<11:41,  2.99s/it]S1/S2 layer (batched):  36%|███▌      | 133/367 [06:38<10:05,  2.59s/it]S1/S2 layer (batched):  37%|███▋      | 134/367 [06:42<11:35,  2.98s/it]S1/S2 layer (batched):  37%|███▋      | 135/367 [06:44<10:00,  2.59s/it]S1/S2 layer (batched):  37%|███▋      | 136/367 [06:48<12:10,  3.16s/it]S1/S2 layer (batched):  37%|███▋      | 137/367 [06:50<10:23,  2.71s/it]S1/S2 layer (batched):  38%|███▊      | 138/367 [06:54<11:42,  3.07s/it]S1/S2 layer (batched):  38%|███▊      | 139/367 [06:55<10:02,  2.64s/it]S1/S2 layer (batched):  38%|███▊      | 140/367 [06:59<11:22,  3.01s/it]S1/S2 layer (batched):  38%|███▊      | 141/367 [07:01<09:47,  2.60s/it]S1/S2 layer (batched):  39%|███▊      | 142/367 [07:05<11:09,  2.98s/it]S1/S2 layer (batched):  39%|███▉      | 143/367 [07:06<09:37,  2.58s/it]S1/S2 layer (batched):  39%|███▉      | 144/367 [07:10<11:02,  2.97s/it]S1/S2 layer (batched):  40%|███▉      | 145/367 [07:12<09:31,  2.57s/it]S1/S2 layer (batched):  40%|███▉      | 146/367 [07:16<10:55,  2.97s/it]S1/S2 layer (batched):  40%|████      | 147/367 [07:17<09:26,  2.57s/it]S1/S2 layer (batched):  40%|████      | 148/367 [07:21<10:27,  2.86s/it]S1/S2 layer (batched):  41%|████      | 149/367 [07:23<09:05,  2.50s/it]S1/S2 layer (batched):  41%|████      | 150/367 [07:26<10:35,  2.93s/it]S1/S2 layer (batched):  41%|████      | 151/367 [07:28<09:06,  2.53s/it]S1/S2 layer (batched):  41%|████▏     | 152/367 [07:33<11:16,  3.15s/it]S1/S2 layer (batched):  42%|████▏     | 153/367 [07:34<09:38,  2.70s/it]S1/S2 layer (batched):  42%|████▏     | 154/367 [07:39<11:33,  3.26s/it]S1/S2 layer (batched):  42%|████▏     | 155/367 [07:41<09:48,  2.77s/it]S1/S2 layer (batched):  43%|████▎     | 156/367 [07:44<10:56,  3.11s/it]S1/S2 layer (batched):  43%|████▎     | 157/367 [07:46<09:21,  2.67s/it]S1/S2 layer (batched):  43%|████▎     | 158/367 [07:50<10:37,  3.05s/it]S1/S2 layer (batched):  43%|████▎     | 159/367 [07:52<09:07,  2.63s/it]S1/S2 layer (batched):  44%|████▎     | 160/367 [07:56<11:03,  3.20s/it]S1/S2 layer (batched):  44%|████▍     | 161/367 [07:58<09:24,  2.74s/it]S1/S2 layer (batched):  44%|████▍     | 162/367 [08:02<10:31,  3.08s/it]S1/S2 layer (batched):  44%|████▍     | 163/367 [08:03<09:01,  2.65s/it]S1/S2 layer (batched):  45%|████▍     | 164/367 [08:07<10:12,  3.02s/it]S1/S2 layer (batched):  45%|████▍     | 165/367 [08:09<08:46,  2.61s/it]S1/S2 layer (batched):  45%|████▌     | 166/367 [08:13<10:04,  3.01s/it]S1/S2 layer (batched):  46%|████▌     | 167/367 [08:15<08:40,  2.60s/it]S1/S2 layer (batched):  46%|████▌     | 168/367 [08:18<09:53,  2.98s/it]S1/S2 layer (batched):  46%|████▌     | 169/367 [08:20<08:32,  2.59s/it]S1/S2 layer (batched):  46%|████▋     | 170/367 [08:24<09:48,  2.99s/it]S1/S2 layer (batched):  47%|████▋     | 171/367 [08:26<08:26,  2.58s/it]S1/S2 layer (batched):  47%|████▋     | 172/367 [08:29<09:39,  2.97s/it]S1/S2 layer (batched):  47%|████▋     | 173/367 [08:31<08:20,  2.58s/it]S1/S2 layer (batched):  47%|████▋     | 174/367 [08:35<09:35,  2.98s/it]S1/S2 layer (batched):  48%|████▊     | 175/367 [08:37<08:15,  2.58s/it]S1/S2 layer (batched):  48%|████▊     | 176/367 [08:41<09:26,  2.97s/it]S1/S2 layer (batched):  48%|████▊     | 177/367 [08:42<08:09,  2.57s/it]S1/S2 layer (batched):  49%|████▊     | 178/367 [08:46<09:23,  2.98s/it]S1/S2 layer (batched):  49%|████▉     | 179/367 [08:48<08:05,  2.58s/it]S1/S2 layer (batched):  49%|████▉     | 180/367 [08:53<10:41,  3.43s/it]S1/S2 layer (batched):  49%|████▉     | 181/367 [08:55<08:58,  2.90s/it]S1/S2 layer (batched):  50%|████▉     | 182/367 [08:59<09:54,  3.22s/it]S1/S2 layer (batched):  50%|████▉     | 183/367 [09:00<08:25,  2.74s/it]S1/S2 layer (batched):  50%|█████     | 184/367 [09:04<09:27,  3.10s/it]S1/S2 layer (batched):  50%|█████     | 185/367 [09:06<08:04,  2.66s/it]S1/S2 layer (batched):  51%|█████     | 186/367 [09:11<09:48,  3.25s/it]S1/S2 layer (batched):  51%|█████     | 187/367 [09:12<08:20,  2.78s/it]S1/S2 layer (batched):  51%|█████     | 188/367 [09:16<09:18,  3.12s/it]S1/S2 layer (batched):  51%|█████▏    | 189/367 [09:18<07:56,  2.68s/it]S1/S2 layer (batched):  52%|█████▏    | 190/367 [09:23<09:44,  3.30s/it]S1/S2 layer (batched):  52%|█████▏    | 191/367 [09:24<08:14,  2.81s/it]S1/S2 layer (batched):  52%|█████▏    | 192/367 [09:28<09:07,  3.13s/it]S1/S2 layer (batched):  53%|█████▎    | 193/367 [09:30<07:47,  2.69s/it]S1/S2 layer (batched):  53%|█████▎    | 194/367 [09:34<08:51,  3.07s/it]S1/S2 layer (batched):  53%|█████▎    | 195/367 [09:35<07:35,  2.65s/it]S1/S2 layer (batched):  53%|█████▎    | 196/367 [09:39<08:35,  3.02s/it]S1/S2 layer (batched):  54%|█████▎    | 197/367 [09:41<07:23,  2.61s/it]S1/S2 layer (batched):  54%|█████▍    | 198/367 [09:45<08:29,  3.02s/it]S1/S2 layer (batched):  54%|█████▍    | 199/367 [09:47<07:17,  2.61s/it]S1/S2 layer (batched):  54%|█████▍    | 200/367 [09:51<08:20,  3.00s/it]S1/S2 layer (batched):  55%|█████▍    | 201/367 [09:52<07:10,  2.59s/it]S1/S2 layer (batched):  55%|█████▌    | 202/367 [09:56<08:13,  2.99s/it]S1/S2 layer (batched):  55%|█████▌    | 203/367 [09:58<07:04,  2.59s/it]S1/S2 layer (batched):  56%|█████▌    | 204/367 [10:02<08:05,  2.98s/it]S1/S2 layer (batched):  56%|█████▌    | 205/367 [10:03<06:58,  2.58s/it]S1/S2 layer (batched):  56%|█████▌    | 206/367 [10:07<07:58,  2.97s/it]S1/S2 layer (batched):  56%|█████▋    | 207/367 [10:09<06:53,  2.58s/it]S1/S2 layer (batched):  57%|█████▋    | 208/367 [10:13<07:54,  2.98s/it]S1/S2 layer (batched):  57%|█████▋    | 209/367 [10:14<06:47,  2.58s/it]S1/S2 layer (batched):  57%|█████▋    | 210/367 [10:18<07:47,  2.98s/it]S1/S2 layer (batched):  57%|█████▋    | 211/367 [10:20<06:42,  2.58s/it]S1/S2 layer (batched):  58%|█████▊    | 212/367 [10:24<07:40,  2.97s/it]S1/S2 layer (batched):  58%|█████▊    | 213/367 [10:25<06:27,  2.52s/it]S1/S2 layer (batched):  58%|█████▊    | 214/367 [10:29<07:18,  2.86s/it]S1/S2 layer (batched):  59%|█████▊    | 215/367 [10:30<06:01,  2.38s/it]S1/S2 layer (batched):  59%|█████▉    | 216/367 [10:34<07:07,  2.83s/it]S1/S2 layer (batched):  59%|█████▉    | 217/367 [10:36<06:11,  2.48s/it]S1/S2 layer (batched):  59%|█████▉    | 218/367 [10:40<07:11,  2.90s/it]S1/S2 layer (batched):  60%|█████▉    | 219/367 [10:41<06:13,  2.52s/it]S1/S2 layer (batched):  60%|█████▉    | 220/367 [10:45<07:10,  2.93s/it]S1/S2 layer (batched):  60%|██████    | 221/367 [10:47<06:12,  2.55s/it]S1/S2 layer (batched):  60%|██████    | 222/367 [10:52<07:45,  3.21s/it]S1/S2 layer (batched):  61%|██████    | 223/367 [10:53<06:34,  2.74s/it]S1/S2 layer (batched):  61%|██████    | 224/367 [10:57<07:20,  3.08s/it]S1/S2 layer (batched):  61%|██████▏   | 225/367 [10:59<06:16,  2.65s/it]S1/S2 layer (batched):  62%|██████▏   | 226/367 [11:03<07:05,  3.02s/it]S1/S2 layer (batched):  62%|██████▏   | 227/367 [11:04<06:05,  2.61s/it]S1/S2 layer (batched):  62%|██████▏   | 228/367 [11:08<06:56,  3.00s/it]S1/S2 layer (batched):  62%|██████▏   | 229/367 [11:10<05:57,  2.59s/it]S1/S2 layer (batched):  63%|██████▎   | 230/367 [11:14<06:47,  2.98s/it]S1/S2 layer (batched):  63%|██████▎   | 231/367 [11:15<05:50,  2.58s/it]S1/S2 layer (batched):  63%|██████▎   | 232/367 [11:19<06:42,  2.98s/it]S1/S2 layer (batched):  63%|██████▎   | 233/367 [11:21<05:45,  2.58s/it]S1/S2 layer (batched):  64%|██████▍   | 234/367 [11:25<06:35,  2.97s/it]S1/S2 layer (batched):  64%|██████▍   | 235/367 [11:26<05:40,  2.58s/it]S1/S2 layer (batched):  64%|██████▍   | 236/367 [11:30<06:30,  2.98s/it]S1/S2 layer (batched):  65%|██████▍   | 237/367 [11:32<05:35,  2.58s/it]S1/S2 layer (batched):  65%|██████▍   | 238/367 [11:36<06:25,  2.99s/it]S1/S2 layer (batched):  65%|██████▌   | 239/367 [11:38<05:30,  2.58s/it]S1/S2 layer (batched):  65%|██████▌   | 240/367 [11:42<06:49,  3.23s/it]S1/S2 layer (batched):  66%|██████▌   | 241/367 [11:44<05:47,  2.76s/it]S1/S2 layer (batched):  66%|██████▌   | 242/367 [11:48<06:28,  3.11s/it]S1/S2 layer (batched):  66%|██████▌   | 243/367 [11:50<05:31,  2.68s/it]S1/S2 layer (batched):  66%|██████▋   | 244/367 [11:54<06:37,  3.23s/it]S1/S2 layer (batched):  67%|██████▋   | 245/367 [11:56<05:36,  2.76s/it]S1/S2 layer (batched):  67%|██████▋   | 246/367 [12:01<06:48,  3.37s/it]S1/S2 layer (batched):  67%|██████▋   | 247/367 [12:02<05:42,  2.86s/it]S1/S2 layer (batched):  68%|██████▊   | 248/367 [12:06<06:16,  3.17s/it]S1/S2 layer (batched):  68%|██████▊   | 249/367 [12:08<05:20,  2.71s/it]S1/S2 layer (batched):  68%|██████▊   | 250/367 [12:13<06:29,  3.33s/it]S1/S2 layer (batched):  68%|██████▊   | 251/367 [12:14<05:27,  2.82s/it]S1/S2 layer (batched):  69%|██████▊   | 252/367 [12:18<06:01,  3.15s/it]S1/S2 layer (batched):  69%|██████▉   | 253/367 [12:20<05:07,  2.70s/it]S1/S2 layer (batched):  69%|██████▉   | 254/367 [12:24<05:45,  3.06s/it]S1/S2 layer (batched):  69%|██████▉   | 255/367 [12:25<04:55,  2.64s/it]S1/S2 layer (batched):  70%|██████▉   | 256/367 [12:30<05:56,  3.21s/it]S1/S2 layer (batched):  70%|███████   | 257/367 [12:32<05:02,  2.75s/it]S1/S2 layer (batched):  70%|███████   | 258/367 [12:36<05:39,  3.11s/it]S1/S2 layer (batched):  71%|███████   | 259/367 [12:37<04:48,  2.67s/it]S1/S2 layer (batched):  71%|███████   | 260/367 [12:42<05:53,  3.30s/it]S1/S2 layer (batched):  71%|███████   | 261/367 [12:44<04:57,  2.81s/it]S1/S2 layer (batched):  71%|███████▏  | 262/367 [12:48<05:30,  3.15s/it]S1/S2 layer (batched):  72%|███████▏  | 263/367 [12:49<04:41,  2.70s/it]S1/S2 layer (batched):  72%|███████▏  | 264/367 [12:54<05:35,  3.26s/it]S1/S2 layer (batched):  72%|███████▏  | 265/367 [12:55<04:43,  2.78s/it]S1/S2 layer (batched):  72%|███████▏  | 266/367 [13:00<05:42,  3.39s/it]S1/S2 layer (batched):  73%|███████▎  | 267/367 [13:02<04:47,  2.88s/it]S1/S2 layer (batched):  73%|███████▎  | 268/367 [13:07<05:40,  3.44s/it]S1/S2 layer (batched):  73%|███████▎  | 269/367 [13:08<04:44,  2.90s/it]S1/S2 layer (batched):  74%|███████▎  | 270/367 [13:12<05:11,  3.21s/it]S1/S2 layer (batched):  74%|███████▍  | 271/367 [13:14<04:23,  2.74s/it]S1/S2 layer (batched):  74%|███████▍  | 272/367 [13:19<05:18,  3.35s/it]S1/S2 layer (batched):  74%|███████▍  | 273/367 [13:20<04:27,  2.84s/it]S1/S2 layer (batched):  75%|███████▍  | 274/367 [13:25<05:18,  3.42s/it]S1/S2 layer (batched):  75%|███████▍  | 275/367 [13:27<04:26,  2.89s/it]S1/S2 layer (batched):  75%|███████▌  | 276/367 [13:31<04:51,  3.20s/it]S1/S2 layer (batched):  75%|███████▌  | 277/367 [13:32<04:06,  2.74s/it]S1/S2 layer (batched):  76%|███████▌  | 278/367 [13:37<04:52,  3.28s/it]S1/S2 layer (batched):  76%|███████▌  | 279/367 [13:39<04:05,  2.79s/it]S1/S2 layer (batched):  76%|███████▋  | 280/367 [13:43<04:54,  3.38s/it]S1/S2 layer (batched):  77%|███████▋  | 281/367 [13:45<04:06,  2.87s/it]S1/S2 layer (batched):  77%|███████▋  | 282/367 [13:49<04:46,  3.37s/it]S1/S2 layer (batched):  77%|███████▋  | 283/367 [13:51<03:59,  2.85s/it]S1/S2 layer (batched):  77%|███████▋  | 284/367 [13:56<04:43,  3.42s/it]S1/S2 layer (batched):  78%|███████▊  | 285/367 [13:58<03:56,  2.89s/it]S1/S2 layer (batched):  78%|███████▊  | 286/367 [14:02<04:36,  3.41s/it]S1/S2 layer (batched):  78%|███████▊  | 287/367 [14:04<03:50,  2.89s/it]S1/S2 layer (batched):  78%|███████▊  | 288/367 [14:08<04:28,  3.39s/it]S1/S2 layer (batched):  79%|███████▊  | 289/367 [14:10<03:43,  2.87s/it]S1/S2 layer (batched):  79%|███████▉  | 290/367 [14:15<04:20,  3.38s/it]S1/S2 layer (batched):  79%|███████▉  | 291/367 [14:16<03:37,  2.87s/it]S1/S2 layer (batched):  80%|███████▉  | 292/367 [14:20<03:59,  3.19s/it]S1/S2 layer (batched):  80%|███████▉  | 293/367 [14:22<03:22,  2.73s/it]S1/S2 layer (batched):  80%|████████  | 294/367 [14:26<03:46,  3.10s/it]S1/S2 layer (batched):  80%|████████  | 295/367 [14:28<03:11,  2.67s/it]S1/S2 layer (batched):  81%|████████  | 296/367 [14:31<03:35,  3.04s/it]S1/S2 layer (batched):  81%|████████  | 297/367 [14:33<03:03,  2.62s/it]S1/S2 layer (batched):  81%|████████  | 298/367 [14:38<03:44,  3.26s/it]S1/S2 layer (batched):  81%|████████▏ | 299/367 [14:39<03:08,  2.78s/it]S1/S2 layer (batched):  82%|████████▏ | 300/367 [14:44<03:46,  3.37s/it]S1/S2 layer (batched):  82%|████████▏ | 301/367 [14:46<03:08,  2.86s/it]S1/S2 layer (batched):  82%|████████▏ | 302/367 [14:50<03:26,  3.17s/it]S1/S2 layer (batched):  83%|████████▎ | 303/367 [14:51<02:54,  2.72s/it]S1/S2 layer (batched):  83%|████████▎ | 304/367 [14:56<03:31,  3.36s/it]S1/S2 layer (batched):  83%|████████▎ | 305/367 [14:58<02:56,  2.85s/it]S1/S2 layer (batched):  83%|████████▎ | 306/367 [15:02<03:13,  3.18s/it]S1/S2 layer (batched):  84%|████████▎ | 307/367 [15:04<02:43,  2.72s/it]S1/S2 layer (batched):  84%|████████▍ | 308/367 [15:08<03:16,  3.33s/it]S1/S2 layer (batched):  84%|████████▍ | 309/367 [15:10<02:44,  2.83s/it]S1/S2 layer (batched):  84%|████████▍ | 310/367 [15:14<03:00,  3.16s/it]S1/S2 layer (batched):  85%|████████▍ | 311/367 [15:16<02:31,  2.71s/it]S1/S2 layer (batched):  85%|████████▌ | 312/367 [15:20<03:02,  3.32s/it]S1/S2 layer (batched):  85%|████████▌ | 313/367 [15:22<02:32,  2.82s/it]S1/S2 layer (batched):  86%|████████▌ | 314/367 [15:26<02:47,  3.15s/it]S1/S2 layer (batched):  86%|████████▌ | 315/367 [15:28<02:20,  2.70s/it]S1/S2 layer (batched):  86%|████████▌ | 316/367 [15:33<02:59,  3.51s/it]S1/S2 layer (batched):  86%|████████▋ | 317/367 [15:35<02:27,  2.95s/it]S1/S2 layer (batched):  87%|████████▋ | 318/367 [15:39<02:48,  3.43s/it]S1/S2 layer (batched):  87%|████████▋ | 319/367 [15:41<02:19,  2.90s/it]S1/S2 layer (batched):  87%|████████▋ | 320/367 [15:46<02:42,  3.46s/it]S1/S2 layer (batched):  87%|████████▋ | 321/367 [15:47<02:14,  2.92s/it]S1/S2 layer (batched):  88%|████████▊ | 322/367 [15:51<02:24,  3.21s/it]S1/S2 layer (batched):  88%|████████▊ | 323/367 [15:53<02:00,  2.74s/it]S1/S2 layer (batched):  88%|████████▊ | 324/367 [15:57<02:21,  3.29s/it]S1/S2 layer (batched):  89%|████████▊ | 325/367 [15:59<01:57,  2.80s/it]S1/S2 layer (batched):  89%|████████▉ | 326/367 [16:03<02:09,  3.16s/it]S1/S2 layer (batched):  89%|████████▉ | 327/367 [16:05<01:48,  2.70s/it]S1/S2 layer (batched):  89%|████████▉ | 328/367 [16:09<01:59,  3.06s/it]S1/S2 layer (batched):  90%|████████▉ | 329/367 [16:10<01:40,  2.64s/it]S1/S2 layer (batched):  90%|████████▉ | 330/367 [16:15<01:59,  3.23s/it]S1/S2 layer (batched):  90%|█████████ | 331/367 [16:16<01:39,  2.76s/it]S1/S2 layer (batched):  90%|█████████ | 332/367 [16:20<01:49,  3.12s/it]S1/S2 layer (batched):  91%|█████████ | 333/367 [16:22<01:31,  2.68s/it]S1/S2 layer (batched):  91%|█████████ | 334/367 [16:26<01:40,  3.04s/it]S1/S2 layer (batched):  91%|█████████▏| 335/367 [16:28<01:23,  2.62s/it]S1/S2 layer (batched):  92%|█████████▏| 336/367 [16:32<01:33,  3.00s/it]S1/S2 layer (batched):  92%|█████████▏| 337/367 [16:33<01:18,  2.60s/it]S1/S2 layer (batched):  92%|█████████▏| 338/367 [16:38<01:35,  3.28s/it]S1/S2 layer (batched):  92%|█████████▏| 339/367 [16:40<01:18,  2.80s/it]S1/S2 layer (batched):  93%|█████████▎| 340/367 [16:43<01:19,  2.95s/it]S1/S2 layer (batched):  93%|█████████▎| 341/367 [16:45<01:06,  2.57s/it]S1/S2 layer (batched):  93%|█████████▎| 342/367 [16:49<01:19,  3.16s/it]S1/S2 layer (batched):  93%|█████████▎| 343/367 [16:51<01:02,  2.60s/it]S1/S2 layer (batched):  94%|█████████▎| 344/367 [16:55<01:13,  3.21s/it]S1/S2 layer (batched):  94%|█████████▍| 345/367 [16:57<01:00,  2.75s/it]S1/S2 layer (batched):  94%|█████████▍| 346/367 [17:01<01:09,  3.31s/it]S1/S2 layer (batched):  95%|█████████▍| 347/367 [17:03<00:56,  2.82s/it]S1/S2 layer (batched):  95%|█████████▍| 348/367 [17:08<01:03,  3.33s/it]S1/S2 layer (batched):  95%|█████████▌| 349/367 [17:09<00:50,  2.83s/it]S1/S2 layer (batched):  95%|█████████▌| 350/367 [17:13<00:53,  3.16s/it]S1/S2 layer (batched):  96%|█████████▌| 351/367 [17:15<00:43,  2.71s/it]S1/S2 layer (batched):  96%|█████████▌| 352/367 [17:19<00:46,  3.07s/it]S1/S2 layer (batched):  96%|█████████▌| 353/367 [17:20<00:37,  2.64s/it]S1/S2 layer (batched):  96%|█████████▋| 354/367 [17:24<00:39,  3.01s/it]S1/S2 layer (batched):  97%|█████████▋| 355/367 [17:26<00:31,  2.60s/it]S1/S2 layer (batched):  97%|█████████▋| 356/367 [17:31<00:35,  3.25s/it]S1/S2 layer (batched):  97%|█████████▋| 357/367 [17:32<00:27,  2.77s/it]S1/S2 layer (batched):  98%|█████████▊| 358/367 [17:37<00:30,  3.38s/it]S1/S2 layer (batched):  98%|█████████▊| 359/367 [17:39<00:22,  2.86s/it]S1/S2 layer (batched):  98%|█████████▊| 360/367 [17:43<00:22,  3.19s/it]S1/S2 layer (batched):  98%|█████████▊| 361/367 [17:44<00:16,  2.73s/it]S1/S2 layer (batched):  99%|█████████▊| 362/367 [17:48<00:15,  3.08s/it]S1/S2 layer (batched):  99%|█████████▉| 363/367 [17:50<00:10,  2.65s/it]S1/S2 layer (batched):  99%|█████████▉| 364/367 [17:55<00:09,  3.28s/it]S1/S2 layer (batched):  99%|█████████▉| 365/367 [17:56<00:05,  2.79s/it]S1/S2 layer (batched): 100%|█████████▉| 366/367 [18:00<00:03,  3.13s/it]S1/S2 layer (batched): 100%|██████████| 367/367 [18:02<00:00,  2.69s/it]S1/S2 layer (batched): 100%|██████████| 367/367 [18:02<00:00,  2.95s/it]


================================================================================
EXPERIMENT SUMMARY
================================================================================
Total examples: 367
Metric: logprob
EM scope: entity
Entity source: gt
Reference scope: continuation
Patch scope: span
Evaluable (non-skipped): 367 (100.0%)
UDS: 0.455
Time: 1084.8s | 2.956s per evaluable example
================================================================================

Log saved to: runs/scale_sanity_8b_dual/8b/retain95/run.log
Detailed JSONL: runs/scale_sanity_8b_dual/8b/retain95/results_detailed.jsonl
Layer CSV: runs/scale_sanity_8b_dual/8b/retain95/layer_details.csv
Skipped examples: runs/scale_sanity_8b_dual/8b/retain95/skipped_examples.json
Results saved to: runs/scale_sanity_8b_dual/8b/retain95/
