=== Faithfulness Evaluation Settings (SDPA/Flash) ===
Date: 2026-02-05

Base Model: Llama-3.2-1B-Instruct (16 layers)
Full Model: open-unlearning/tofu_Llama-3.2-1B-Instruct_full
Retain Model: open-unlearning/tofu_Llama-3.2-1B-Instruct_retain90

Attention: SDPA (Scaled Dot-Product Attention / Flash)
Batch Size: 32
Chat Template: Yes (Llama Instruct, date="10 Apr 2025")

P/N Pool: 60 models (30 P + 30 N)
  - P-pool: Models trained on forget10 (have knowledge)
  - N-pool: Models NOT trained on forget10 (no knowledge)

=== 13 Metrics ===
Memorization (5):
  - EM: Exact Match
  - ES: Extraction Strength (Carlini suffix)
  - Probability: exp(-avg_loss) on GT
  - Para.Prob: GM of exp(-loss) on paraphrases
  - Truth Ratio: para/(para+wrong)

Generation (3):
  - ROUGE: rougeL recall vs GT
  - Para.ROUGE: rougeL recall vs paraphrases (mean)
  - Jailbreak ROUGE: with "Sure, here is the answer:" prefix

Privacy/MIA (4):
  - MIA-LOSS: AUC-ROC (loss)
  - MIA-ZLib: AUC-ROC (loss/zlib_entropy)
  - MIA-MinK: AUC-ROC (k=0.4)
  - MIA-MinK++: AUC-ROC (z-score variant)

Ours (1):
  - UDS: 1 - Unlearning Depth Score (367 examples, v7_gt)

=== Data ===
12 standard metrics: forget10_perturbed (400 examples)
UDS: v7_gt (367 examples, Full-Wrong 33 excluded)

=== Output ===
12 metrics: runs/meta_eval/table2_faithfulness_v3_gpu{0,1}/
UDS: runs/meta_eval/table2_faithfulness_uds_sdpa_gpu{0,1}/
