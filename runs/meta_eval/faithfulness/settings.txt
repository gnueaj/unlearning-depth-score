=== Faithfulness Evaluation Settings ===
Date: 2026-02-07 (updated)

Base Model: Llama-3.2-1B-Instruct (16 layers)
Full Model: open-unlearning/tofu_Llama-3.2-1B-Instruct_full
Retain Model: open-unlearning/tofu_Llama-3.2-1B-Instruct_retain90

Attention: Eager (for S1 cache consistency in faithfulness)
Batch Size: 32
Chat Template: Yes (Llama Instruct)

P/N Pool: 60 models (30 P + 30 N)
  - P-pool: Models trained on forget10 (have knowledge)
  - N-pool: Models NOT trained on forget10 (no knowledge)

=== 13 Metrics ===
Memorization (5):
  - EM: Exact Memorization
  - ES: Extraction Strength (Carlini suffix)
  - Probability: exp(-avg_loss) on GT
  - Para.Prob: GM of exp(-loss) on paraphrases
  - Truth Ratio: para/(para+wrong)

Generation (3):
  - ROUGE: rougeL recall vs GT
  - Para.ROUGE: rougeL recall vs paraphrases (mean)
  - Jailbreak ROUGE: with "Sure, here is the answer:" prefix

Privacy/MIA (4):
  - MIA-LOSS: AUC-ROC (loss)
  - MIA-ZLib: AUC-ROC (loss/zlib_entropy)
  - MIA-MinK: AUC-ROC (k=0.4)
  - MIA-MinK++: AUC-ROC (z-score variant)

Ours (1):
  - 1-UDS: Unlearning Depth Score (367 examples, s1_cache_v2)

=== Data ===
12 standard metrics: forget10_perturbed (400 examples)
UDS: tofu_data/forget10_filtered_v7_gt.json (367 examples)

=== Output ===
Results: runs/meta_eval/faithfulness/results.json
Summary: runs/meta_eval/faithfulness/summary.json
UDS eager: runs/meta_eval/faithfulness/uds_eager.json (s1_cache_eager 기반, eager attention)
